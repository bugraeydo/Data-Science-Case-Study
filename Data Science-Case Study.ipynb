{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cee1be9",
   "metadata": {},
   "source": [
    "# Case Study\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6493705f",
   "metadata": {},
   "source": [
    "# Problem 1 \n",
    "\n",
    "In this problem, you are going to build predictive models on the estimation of energy performance of residential buildings.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "You are given `ENB2012_data.xlsx` file. You can also get the dataset from the following link: http://archive.ics.uci.edu/ml/datasets/energy+efficiency. The dataset comprises 768 samples and 8 features. The features are:\n",
    "\n",
    "1. Relative compactness\n",
    "2. Surface area\n",
    "3. Wall area\n",
    "4. Roof area\n",
    "5. Overall height\n",
    "6. Orientation\n",
    "7. Glazing area\n",
    "8. Glazing area distribution\n",
    "\n",
    "The two output variables are heating load (HL) and cooling load (CL) of residential buildings. Machine learning models can be used to predict heating and cooling loads for the aforementioned features of a building.\n",
    "\n",
    "## Scientific Article\n",
    "\n",
    "There is a scientific article which provides some analysis on this data set: A. Tsanas, A. Xifara: 'Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools', Energy and Buildings, Vol. 49, pp. 560-567, 2012.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12e89609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_excel_data(filename):\n",
    "    data = pd.read_excel(filename)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4fecc023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_excel_data('ENB2012_data.xlsx')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeaf6b7",
   "metadata": {},
   "source": [
    "\n",
    "In this problem, you are asked to build a predictive model using Ridge Regression. Please perform the following tasks:\n",
    "\n",
    "## Task 1\n",
    "\n",
    "1. Build a predictive model using Ridge Regression.\n",
    "2. Test the ridge model with the following alpha parameters: 0.001, 0.01, 0.1, 1.0, and 10.0.\n",
    "3. Find the optimal alpha parameter that gives the best results.\n",
    "4. Using the optimal alpha parameter, calculate the Mean Absolute Error (MAE) and Mean Squared Error (MSE) using 10-fold cross-validation with 10 repetitions and randomly chosen data.\n",
    "5. Calculate the mean score and standard deviation for these cross-validations.\n",
    "\n",
    "After completing these tasks, you should have a predictive model that accurately estimates the energy performance of residential buildings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f336d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f1adcd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_with_grid_search(data, alphas, n_folds, n_repeats):\n",
    "\n",
    "    # Split the dataset into features (X) and target variables (y)\n",
    "    X = data.iloc[:, :-2].values\n",
    "    y = data.iloc[:, -2:].values\n",
    "\n",
    "    # Define the Ridge Regression model\n",
    "    ridge = Ridge()\n",
    "\n",
    "    # Define the grid search parameters\n",
    "    param_grid = {'alpha': alphas}\n",
    "\n",
    "    # Define the cross-validation parameters\n",
    "    kf = RepeatedKFold(n_splits=n_folds, n_repeats=n_repeats, random_state=42)\n",
    "\n",
    "    # Perform grid search cross-validation to find the optimal alpha parameter\n",
    "    grid_search = GridSearchCV(ridge, param_grid=param_grid, scoring='neg_mean_absolute_error', cv=kf, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Print the optimal alpha parameter\n",
    "    print(\"Optimal alpha parameter: \", grid_search.best_params_)\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e117763f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha parameter:  {'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "n_folds = 10\n",
    "n_repeats = 10\n",
    "\n",
    "result = ridge_regression_with_grid_search(data, alphas, n_folds, n_repeats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5c15c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_with_cv(data, alpha=0.001, n_folds=10, n_repeats=10, random_state=42):\n",
    "    \n",
    "    # Split the dataset into features (X) and target variables (Y1, Y2)\n",
    "    X = data.iloc[:, :-2].values\n",
    "    Y1 = data.iloc[:, -2].values\n",
    "    Y2 = data.iloc[:, -1].values\n",
    "    \n",
    "    # Set up the ridge regression model with alpha\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "\n",
    "    # Set up cross-validation parameters\n",
    "    kf = cv = RepeatedKFold(n_splits=n_folds, n_repeats=n_repeats, random_state=random_state)\n",
    "\n",
    "    # Calculate Mean Absolute Error and Mean Squared Errors scores for Y1\n",
    "    mae_scores_y1 = cross_val_score(ridge, X, Y1, scoring='neg_mean_absolute_error', cv=kf, n_jobs=-1, \n",
    "                                    error_score='raise')\n",
    "    mse_scores_y1 = cross_val_score(ridge, X, Y1, scoring='neg_mean_squared_error', cv=kf, n_jobs=-1, \n",
    "                                    error_score='raise')\n",
    "\n",
    "    # Calculate Mean Absolute Error and Mean Squared Errors scores for Y2\n",
    "    mae_scores_y2 = cross_val_score(ridge, X, Y2, scoring='neg_mean_absolute_error', cv=kf, n_jobs=-1, \n",
    "                                    error_score='raise')\n",
    "    mse_scores_y2 = cross_val_score(ridge, X, Y2, scoring='neg_mean_squared_error', cv=kf, n_jobs=-1, \n",
    "                                    error_score='raise')\n",
    "\n",
    "    # Calculate mean and standard deviation of the scores for Y1\n",
    "    mae_mean_y1 = np.mean(-mae_scores_y1)\n",
    "    mae_std_y1 = np.std(-mae_scores_y1)\n",
    "    mse_mean_y1 = np.mean(-mse_scores_y1)\n",
    "    mse_std_y1 = np.std(-mse_scores_y1)\n",
    "\n",
    "    # Calculate mean and standard deviation of the scores for Y2\n",
    "    mae_mean_y2 = np.mean(-mae_scores_y2)\n",
    "    mae_std_y2 = np.std(-mae_scores_y2)\n",
    "    mse_mean_y2 = np.mean(-mse_scores_y2)\n",
    "    mse_std_y2 = np.std(-mse_scores_y2)\n",
    "\n",
    "    # Print the results as a table\n",
    "    print(\"Ridge Regression Results\")\n",
    "    print(\"Y1 Output\")\n",
    "    print(\"MAE: {:.3f} +/- {:.3f}\".format(mae_mean_y1, mae_std_y1))\n",
    "    print(\"MSE: {:.3f} +/- {:.3f}\".format(mse_mean_y1, mse_std_y1))\n",
    "    print()\n",
    "    print(\"Y2 Output\")\n",
    "    print(\"MAE: {:.3f} +/- {:.3f}\".format(mae_mean_y2, mae_std_y2))\n",
    "    print(\"MSE: {:.3f} +/- {:.3f}\".format(mse_mean_y2, mse_std_y2))\n",
    "    \n",
    "    return mae_mean_y1,mae_std_y1,mse_mean_y1,mse_std_y1,mae_mean_y2,mae_std_y2,mse_mean_y2,mse_std_y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "112001eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Results\n",
      "Y1 Output\n",
      "MAE: 2.087 +/- 0.242\n",
      "MSE: 8.685 +/- 1.766\n",
      "\n",
      "Y2 Output\n",
      "MAE: 2.266 +/- 0.272\n",
      "MSE: 10.344 +/- 2.720\n"
     ]
    }
   ],
   "source": [
    "mae_mean_y1,mae_std_y1,mse_mean_y1,mse_std_y1,mae_mean_y2,mae_std_y2,mse_mean_y2,mse_std_y2=ridge_regression_with_cv(data, alpha=0.001, n_folds=10, n_repeats=10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7f885",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Task 2\n",
    "\n",
    "1. Using GridSearch, find the optimal values for the following parameters for RandomForestRegressor:\n",
    "\n",
    "    ```\n",
    "    parameters = {\n",
    "        \"clf_n_estimators\":(10,50,100,250,500),\n",
    "        \"clf_max_depth\":(50,150,250),\n",
    "        \"clf_min_samples_split\":(2,3),\n",
    "        \"clf_min_samples_leaf\":(1,2,3),\n",
    "    }\n",
    "    ```\n",
    "\n",
    "2. Report the optimal values you found.\n",
    "\n",
    "3. Using the optimal parameters, calculate the Mean Absolute Error (MAE) and Mean Squared Error (MSE) scores for 10-fold cross-validation with 10 repetitions and randomly chosen data.\n",
    "\n",
    "4. Calculate the mean and standard deviation of the scores for cross-validations.\n",
    "\n",
    "5. Repeat steps 1-4 separately for Y1 and Y2 outputs.\n",
    "\n",
    "After completing these tasks, you should have two separate predictive models for heating load (Y1) and cooling load (Y2) of residential buildings, which accurately estimate their energy performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5d82468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"clf_n_estimators\":(10,50,100,250,500),\n",
    "    \"clf_max_depth\":(50,150,250),\n",
    "    \"clf_min_samples_split\":(2,3),\n",
    "    \"clf_min_samples_leaf\":(1,2,3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9487302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_grid_search(data):\n",
    "    \n",
    "    # Split the dataset into features (X) and target variables (y)\n",
    "    X = data.iloc[:, :-2].values\n",
    "    y = data.iloc[:, -2:].values\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [10, 50, 100, 250, 500],\n",
    "        \"max_depth\": [50, 150, 250],\n",
    "        \"min_samples_split\": [2, 3],\n",
    "        \"min_samples_leaf\": [1, 2, 3]\n",
    "    }\n",
    "\n",
    "    # Create a RandomForestRegressor object\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=rf,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        cv=10,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Return the optimal parameters\n",
    "    return grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b8b934cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters: {'max_depth': 50, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "optimal_params = random_forest_grid_search(data)\n",
    "print(\"Optimal parameters:\", optimal_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd8eef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf_regressor(data, opt_params, num_repeats=10, num_folds=10, random_state=42):\n",
    "\n",
    "    # Split the dataset into features (X) and target variables (Y1, Y2)\n",
    "    X = data.iloc[:, :-2].values\n",
    "    y1 = data.iloc[:, -2].values\n",
    "    y2 = data.iloc[:, -1].values\n",
    "    \n",
    "\n",
    "    # Define the cross validation strategy\n",
    "    cv_strategy = RepeatedKFold(n_splits=n_folds, n_repeats=n_repeats, random_state=random_state)\n",
    "\n",
    "    # Define the regressor with optimal parameters\n",
    "    rf_regressor_y1 = RandomForestRegressor(**opt_params, random_state=random_state)\n",
    "    rf_regressor_y2 = RandomForestRegressor(**opt_params, random_state=random_state)\n",
    "\n",
    "    # Calculate the cross validation scores using mean absolute error and mean squared error for Y1 output\n",
    "    y1_mae_scores = cross_val_score(rf_regressor_y1, X, y1, cv=cv_strategy, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    y1_mse_scores = cross_val_score(rf_regressor_y1, X, y1, cv=cv_strategy, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "    # Calculate the cross validation scores using mean absolute error and mean squared error for Y2 output\n",
    "    y2_mae_scores = cross_val_score(rf_regressor_y2, X, y2, cv=cv_strategy, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    y2_mse_scores = cross_val_score(rf_regressor_y2, X, y2, cv=cv_strategy, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "    # Convert the negative scores to positive\n",
    "    y1_mae_scores = -y1_mae_scores\n",
    "    y1_mse_scores = -y1_mse_scores\n",
    "    y2_mae_scores = -y2_mae_scores\n",
    "    y2_mse_scores = -y2_mse_scores\n",
    "\n",
    "    # Calculate the mean and standard deviation of the cross validation scores for Y1 output\n",
    "    y1_mae_mean = y1_mae_scores.mean()\n",
    "    y1_mae_std = y1_mae_scores.std()\n",
    "    y1_mse_mean = y1_mse_scores.mean()\n",
    "    y1_mse_std = y1_mse_scores.std()\n",
    "\n",
    "    # Calculate the mean and standard deviation of the cross validation scores for Y2 output\n",
    "    y2_mae_mean = y2_mae_scores.mean()\n",
    "    y2_mae_std = y2_mae_scores.std()\n",
    "    y2_mse_mean = y2_mse_scores.mean()\n",
    "    y2_mse_std = y2_mse_scores.std()\n",
    "\n",
    "    # Print the results in a table\n",
    "    print(\"Results for Y1 output:\")\n",
    "    print(\"MAE: {:.2f} +/- {:.2f}\".format(y1_mae_mean, y1_mae_std))\n",
    "    print(\"RMSE: {:.2f} +/- {:.2f}\".format(y1_mse_mean, y1_mse_std))\n",
    "\n",
    "    print(\"\\nResults for Y2 output:\")\n",
    "    print(\"MAE: {:.2f} +/- {:.2f}\".format(y2_mae_mean, y2_mae_std))\n",
    "    print(\"RMSE: {:.2f} +/- {:.2f}\".format(y2_mse_mean, y2_mse_std))\n",
    "    \n",
    "    return y1_mae_mean,y1_mae_std,y1_mse_mean,y1_mse_std,y2_mae_mean,y2_mae_std,y2_mse_mean,y2_mse_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97f5cde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Y1 output:\n",
      "MAE: 0.31 +/- 0.04\n",
      "RMSE: 0.22 +/- 0.06\n",
      "\n",
      "Results for Y2 output:\n",
      "MAE: 0.98 +/- 0.14\n",
      "RMSE: 2.63 +/- 0.68\n"
     ]
    }
   ],
   "source": [
    "y1_mae_mean,y1_mae_std,y1_mse_mean,y1_mse_std,y2_mae_mean,y2_mae_std,y2_mse_mean,y2_mse_std= run_rf_regressor(data, optimal_params, num_repeats=10, num_folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3e56e",
   "metadata": {},
   "source": [
    "In your report, provide a table like given below for the scores. The values in the tables are mean and\n",
    "standart deviations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d7dec70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_results(y1_mae_mean, y1_mae_std, y1_mse_mean, y1_mse_std, mae_mean_y1, mae_std_y1, mse_mean_y1, mse_std_y1, y2_mae_mean, y2_mae_std, y2_mse_mean, y2_mse_std, mae_mean_y2, mae_std_y2, mse_mean_y2, mse_std_y2):\n",
    "    \n",
    "    # Results for Y1\n",
    "    y1_rf_mae = y1_mae_mean\n",
    "    y1_rf_mae_std = y1_mae_std\n",
    "    y1_rf_mse = y1_mse_mean\n",
    "    y1_rf_mse_std = y1_mse_std\n",
    "    y1_ridge_mae = mae_mean_y1\n",
    "    y1_ridge_mae_std = mae_std_y1\n",
    "    y1_ridge_mse = mse_mean_y1\n",
    "    y1_ridge_mse_std = mse_std_y1\n",
    "\n",
    "    # Results for Y2\n",
    "    y2_rf_mae = y2_mae_mean\n",
    "    y2_rf_mae_std = y2_mae_std\n",
    "    y2_rf_mse = y2_mse_mean\n",
    "    y2_rf_mse_std = y2_mse_std\n",
    "    y2_ridge_mae = mae_mean_y2\n",
    "    y2_ridge_mae_std = mae_std_y2\n",
    "    y2_ridge_mse = mse_mean_y2\n",
    "    y2_ridge_mse_std = mse_std_y2\n",
    "\n",
    "    # Create the table\n",
    "    print(\"{:^10} {:^20} {:^20} {:^25} {:^25}\".format(\"\", \"Mean Absolute Error\", \"Root Mean Squared Error\", \"\", \"\"))\n",
    "    print(\"{:^10} {:^20} {:^20} {:^25} {:^25}\".format(\"Output\", \"RandomForest\", \"RidgeRegression\", \"RandomForest\", \"RidgeRegression\"))\n",
    "    print(\"{:^10} {:^20} {:^20} {:^25} {:^25}\".format(\"Y1\", \"{:.2f} ± {:.2f}\".format(y1_rf_mae, y1_rf_mae_std), \"{:.2f} ± {:.2f}\".format(y1_ridge_mae, y1_ridge_mae_std), \"{:.2f} ± {:.2f}\".format(y1_rf_mse, y1_rf_mse_std), \"{:.2f} ± {:.2f}\".format(y1_ridge_mse, y1_ridge_mse_std)))\n",
    "    print(\"{:^10} {:^20} {:^20} {:^25} {:^25}\".format(\"Y2\", \"{:.2f} ± {:.2f}\".format(y2_rf_mae, y2_rf_mae_std), \"{:.2f} ± {:.2f}\".format(y2_ridge_mae, y2_ridge_mae_std), \"{:.2f} ± {:.2f}\".format(y2_rf_mse, y2_rf_mse_std), \"{:.2f} ± {:.2f}\".format(y2_ridge_mse, y2_ridge_mse_std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e772d868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Mean Absolute Error  Root Mean Squared Error                                                    \n",
      "  Output       RandomForest       RidgeRegression          RandomForest             RidgeRegression     \n",
      "    Y1         0.31 ± 0.04          2.09 ± 0.24             0.22 ± 0.06               8.68 ± 1.77       \n",
      "    Y2         0.98 ± 0.14          2.27 ± 0.27             2.63 ± 0.68              10.34 ± 2.72       \n"
     ]
    }
   ],
   "source": [
    "print_regression_results(y1_mae_mean,y1_mae_std,y1_mse_mean, y1_mse_std, \n",
    "              mae_mean_y1, mae_std_y1, mse_mean_y1, mse_std_y1,\n",
    "              y2_mae_mean, y2_mae_std, y2_mse_mean, y2_mse_std,\n",
    "              mae_mean_y2, mae_std_y2, mse_mean_y2, mse_std_y2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1379ee1b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Problem 2 \n",
    "\n",
    "In this problem, you are going to build predictive models for bank telemarketing problem. The data is\n",
    "related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns\n",
    "were based on phone calls. Often, more than one contact to the same client was required, in order to\n",
    "access if the product (bank term deposit) would be ('yes') or not ('no') subscribed.\n",
    "\n",
    "## Dataset\n",
    "\n",
    " You are given bankadditional-full.csv file containing the data set. The dataset can also be obtained from https://archive.ics.uci.edu/ml/datasets/bank+marketing The features are:\n",
    "\n",
    "1. age (numeric)\n",
    "2. job: type of job (categorical: 'admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown')\n",
    "3. marital: marital status (categorical: 'divorced', 'married', 'single', 'unknown'; note: 'divorced' means divorced or widowed)\n",
    "4. education (categorical: 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown')\n",
    "5. default: has credit in default? (categorical: 'no', 'yes', 'unknown')\n",
    "6. housing: has housing loan? (categorical: 'no', 'yes', 'unknown')\n",
    "7. loan: has personal loan? (categorical: 'no', 'yes', 'unknown')\n",
    "8. contact: contact communication type (categorical: 'cellular', 'telephone')\n",
    "9. month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10. day_of_week: last contact day of the week (categorical: 'mon', 'tue', 'wed', 'thu', 'fri')\n",
    "11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14. previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15. poutcome: outcome of the previous marketing campaign (categorical: 'failure', 'nonexistent', 'success')\n",
    "16. emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17. cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18. cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19. euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20. nr.employed: number of employees - quarterly indicator (numeric)\n",
    "The output variable is:\n",
    "\n",
    "21. y: has the client subscribed a term deposit? (binary: 'yes', 'no')\n",
    "\n",
    "\n",
    "## Scientific Article\n",
    "\n",
    "The\n",
    "following article describes some analysis on this dataset: S. Moro, P. Cortez and P. Rita. A DataDriven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier,\n",
    "62:22-31, June 2014.\n",
    "\n",
    "You are going to build predictive models for the prediction of the ouput whether a given client will\n",
    "subscrive a term deposit or not. You will use data in “bank-additional-full.csv” file. Some attributes\n",
    "have “unknown” or “nonexistent” categories. Don’t bother to clean this data. You can consider them\n",
    "as a category in that attribute. Note that you may not get the exact results with results given in the\n",
    "assignment. Slightly different results are fine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1afa1e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(filename):\n",
    "    df = pd.read_csv(filename, sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1522440e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_csv_data('bank-additional-full.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95311282",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Task 1\n",
    "\n",
    "Build a logistic regression model following the instructions given below:\n",
    "\n",
    "1. Use AUC metric for scoring the model.\n",
    "2. Use 5-fold cross-validation with 5 repetitions for cross-validation.\n",
    "3. Select data randomly in cross-validation.\n",
    "4. Find the C parameter which gives the highest AUC score.\n",
    "5. Note that C is a hyperparameter in Logistic Regression which means Inverse of regularization strength.\n",
    "6. Try the model with 20 different C parameters.\n",
    "7. C parameters should range from 10^-4 to 10^4.\n",
    "8. Plot mean AUC score vs C parameter.\n",
    "\n",
    "Please note that the calculation takes some time since you will train and test the model for 500 times. Your figure should look like the one given below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "323e2f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70fe3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_C(data, C_range, num_repeats, num_folds,random_state=1):\n",
    "    # Define the input and target variables\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "\n",
    "    # Convert categorical variables to dummy variables\n",
    "    X = pd.get_dummies(X)\n",
    "\n",
    "    # Set up the RepeatedKFold cross-validator\n",
    "    rkf = RepeatedKFold(n_splits=num_folds, n_repeats=num_repeats, random_state=random_state)\n",
    "\n",
    "    # Set up an empty list to store the mean AUC scores for each value of C\n",
    "    mean_auc_scores = []\n",
    "\n",
    "    # Loop over each value of C\n",
    "    for C in C_range:\n",
    "        # Set up the logistic regression model\n",
    "        lr = LogisticRegression(C=C, penalty='l2', solver='liblinear', random_state=random_state)\n",
    "\n",
    "        # Set up an empty list to store the AUC scores for each fold\n",
    "        auc_scores = []\n",
    "\n",
    "        # Loop over each fold of the cross-validator\n",
    "        for train_idx, test_idx in rkf.split(X):\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "\n",
    "            # Scale the input variables\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # Fit the logistic regression model to the training data\n",
    "            lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "            # Predict the probability of the target variable for the test data\n",
    "            y_prob = lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "            # Calculate the AUC score for the test data\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "            # Append the AUC score to the list of AUC scores for this value of C\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "        # Calculate the mean AUC score for this value of C\n",
    "        mean_auc = np.mean(auc_scores)\n",
    "\n",
    "        # Append the mean AUC score to the list of mean AUC scores for each value of C\n",
    "        mean_auc_scores.append(mean_auc)\n",
    "\n",
    "    # Find the index of the maximum mean AUC score\n",
    "    max_auc_idx = np.argmax(mean_auc_scores)\n",
    "\n",
    "    # Find the value of C that gives the maximum mean AUC score\n",
    "    best_C = C_range[max_auc_idx]\n",
    "\n",
    "    # Plot mean AUC score vs C\n",
    "    plt.plot(C_range, mean_auc_scores)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('C')\n",
    "    plt.ylabel('Mean AUC Score')\n",
    "    plt.title('Logistic Regression')\n",
    "    plt.show()\n",
    "\n",
    "    return best_C, round(mean_auc_scores[max_auc_idx], 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ad2a4e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best C value is 0.615848211066026 with a mean AUC score of 0.935\n"
     ]
    }
   ],
   "source": [
    "C_range = np.logspace(-4, 4, 20)\n",
    "num_repeats = 5\n",
    "num_folds = 5\n",
    "best_C, mean_auc_score = find_best_C(df, C_range, num_repeats, num_folds)\n",
    "print(\"The best C value is\", best_C, \"with a mean AUC score of\", (mean_auc_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394f507",
   "metadata": {},
   "source": [
    "## Task 2 : Build a Random Forest model.\n",
    "\n",
    "Follow the instructions given when building the model. Using gridsearch try to find the best score and combination of the following hyperparameters:\n",
    "\n",
    "- Number of estimators: 10, 50, 100, 250, 500, 1000\n",
    "- Max depth: 50, 150, 250\n",
    "- Min samples split: 2, 3\n",
    "- Min samples leaf: 1, 2, 3\n",
    "\n",
    "For cross-validation in grid search use a cross validation strategy as 3-fold cross-validation with 3 repetitions.\n",
    "\n",
    "Report the hyperparameter set yielding the best score. For scoring use AUC score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e5b72a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_random_forest(df,param_grid,n_splits=3, n_repeats=3,random_state=1):\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    df = pd.get_dummies(df, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'])\n",
    "\n",
    "    # Split into features and target\n",
    "    X = df.drop('y', axis=1)\n",
    "    y = df['y']\n",
    "\n",
    "    # create random forest classifier\n",
    "    rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "    # set up cross-validation strategy for grid search\n",
    "    cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "\n",
    "    # perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=rfc,\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # fit grid search to data\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # get best hyperparameters and corresponding score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    # return best hyperparameters and corresponding score\n",
    "    return best_params, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0d31a69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 50, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 1000}\n",
      "Best score: 0.9446425353004856\n"
     ]
    }
   ],
   "source": [
    "# set up parameter grid for grid search\n",
    "param_grid = {\n",
    "        'n_estimators': [10, 50, 100, 250, 500, 1000],\n",
    "        'max_depth': [50, 150, 250],\n",
    "        'min_samples_split': [2, 3],\n",
    "        'min_samples_leaf': [1, 2, 3]\n",
    "    }\n",
    "\n",
    "best_params, best_score = grid_search_random_forest(df,param_grid)\n",
    "print('Best hyperparameters:', best_params)\n",
    "print('Best score:', best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e135a5a6",
   "metadata": {},
   "source": [
    "## Task 3 : Build a neural network model:\n",
    "Follow the instructions given when building the model.\n",
    "First, scale your input data so that it has zero mean and one standart deviation. This is important because neural network models are sensitive to input scaling.\n",
    "Then using gridsearch try to find the best score and combination of the following hyperparameters:\n",
    "\n",
    "- Hidden_layer_sizes: (10,10,10), (10,10,10,10), (10,10,10,10,10), (10,10,10,10,10,10)\n",
    "- Alpha: 0.00001, 0.0001, 0.001, 0.01, 0.1\n",
    "\n",
    "In grid search, use AUC score as scoring. For cross-validation in grid search, use a cross-validation strategy as 3-fold cross-validation with 3 repetitions.\n",
    "\n",
    "Report the hyperparameter set yielding the best score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55d2dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_neural_network_model(df,param_grid,n_splits=3, n_repeats=3,random_state=1):\n",
    "\n",
    "    # Preprocess data\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1].map({'no': 0, 'yes': 1})\n",
    "    X = pd.get_dummies(X, drop_first=True)  # Convert categorical variables to numerical\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)  # Scale input data\n",
    "\n",
    "    # Define neural network model\n",
    "    mlp = MLPClassifier(random_state=1)\n",
    "\n",
    "    # set up cross-validation strategy for grid search\n",
    "    cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
    "\n",
    "    # Define grid search with AUC as scoring metric and 3-fold cross-validation\n",
    "    grid_search = GridSearchCV(mlp, param_grid=param_grid, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\n",
    "    # Fit grid search to data\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Print best hyperparameters and corresponding AUC score\n",
    "    print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best AUC score: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9aa7682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'alpha': 0.1, 'hidden_layer_sizes': (10, 10, 10)}\n",
      "Best AUC score:  0.939528587311741\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter search space\n",
    "param_grid = {'hidden_layer_sizes': [(10, 10, 10), (10, 10, 10, 10), (10, 10, 10, 10, 10)],\n",
    "                  'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
    "\n",
    "run_neural_network_model(df,n_splits=3, n_repeats=3,param_grid=param_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717936f9",
   "metadata": {},
   "source": [
    "\n",
    "## Task 4 : Prepare a classification report for three models\n",
    "In this task, we will perform 5-fold cross-validation with randomly splitting data. For each model, we will print the average classification report for this 5-fold cross-validation.\n",
    "We will use the following models:\n",
    "\n",
    "- Logistic Regression with C=1\n",
    "- Random Forest with optimal hyperparameters found in Task2\n",
    "- Neural Network with optimal hyperparameters found in Task3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7d5266a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "AUC: 0.935 +/- 0.003\n",
      "\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.97      0.95     36548\n",
      "         yes       0.67      0.42      0.52      4640\n",
      "\n",
      "    accuracy                           0.91     41188\n",
      "   macro avg       0.80      0.70      0.74     41188\n",
      "weighted avg       0.90      0.91      0.90     41188\n",
      "\n",
      "Random Forest:\n",
      "AUC: 0.945 +/- 0.002\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.96      0.99      0.98     36548\n",
      "         yes       0.93      0.70      0.80      4640\n",
      "\n",
      "    accuracy                           0.96     41188\n",
      "   macro avg       0.94      0.85      0.89     41188\n",
      "weighted avg       0.96      0.96      0.96     41188\n",
      "\n",
      "Neural Network:\n",
      "AUC: 0.941 +/- 0.003\n",
      "\n",
      "Classification Report for Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.95      0.96      0.96     36548\n",
      "         yes       0.66      0.61      0.63      4640\n",
      "\n",
      "    accuracy                           0.92     41188\n",
      "   macro avg       0.81      0.78      0.79     41188\n",
      "weighted avg       0.92      0.92      0.92     41188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical variables\n",
    "df = pd.get_dummies(df, columns=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome'])\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)  # Scale input data\n",
    "\n",
    "logreg = LogisticRegression(C=1, solver='lbfgs', max_iter=1000)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "logreg_scores = cross_val_score(logreg, X, y, cv=cv, scoring='roc_auc')\n",
    "logreg_mean_score = logreg_scores.mean()\n",
    "logreg_std_score = logreg_scores.std()\n",
    "print(f'Logistic Regression:\\nAUC: {logreg_mean_score:.3f} +/- {logreg_std_score:.3f}\\n')\n",
    "logreg.fit(X, y)\n",
    "y_pred_logreg = logreg.predict(X)\n",
    "print('Classification Report for Logistic Regression:')\n",
    "print(classification_report(y, y_pred_logreg))\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=150, min_samples_split=3, min_samples_leaf=3, random_state=42)\n",
    "rf_scores = cross_val_score(rf, X, y, cv=cv, scoring='roc_auc')\n",
    "rf_mean_score = rf_scores.mean()\n",
    "rf_std_score = rf_scores.std()\n",
    "print(f'Random Forest:\\nAUC: {rf_mean_score:.3f} +/- {rf_std_score:.3f}\\n')\n",
    "rf.fit(X, y)\n",
    "y_pred_rf = rf.predict(X)\n",
    "print('Classification Report for Random Forest:')\n",
    "print(classification_report(y, y_pred_rf))\n",
    "\n",
    "\n",
    "nn = MLPClassifier(hidden_layer_sizes=(10, 10, 10), alpha=0.1, max_iter=200, random_state=42)\n",
    "nn_scores = cross_val_score(nn, X, y, cv=cv, scoring='roc_auc')\n",
    "nn_mean_score = nn_scores.mean()\n",
    "nn_std_score = nn_scores.std()\n",
    "print(f'Neural Network:\\nAUC: {nn_mean_score:.3f} +/- {nn_std_score:.3f}\\n')\n",
    "nn.fit(X, y)\n",
    "y_pred_nn = nn.predict(X)\n",
    "print('Classification Report for Neural Network:')\n",
    "print(classification_report(y, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c34a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
